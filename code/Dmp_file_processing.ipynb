{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading Names.dmp and then Nodes.dmp files.\n",
    "#Combining two files based on their Tax_id's to obtain a final file that is loaded into Neo4j\n",
    "import re\n",
    "import csv\n",
    "import pandas as pd\n",
    "dmp_file = open(r'C:\\Users\\GURU\\Desktop\\tax_data 26-3\\names.dmp',\"r\", encoding=\"utf-8\").read()\n",
    "#dmp_file=dmp_file[0:4000]\n",
    "dmp_file = re.sub('\\s+', '', dmp_file) #Removing \\t from file\n",
    "dmp_file=re.sub(',','',dmp_file)       #Removing , from file as it causes issues\n",
    "dmp_file= dmp_file.replace('|', ',')   #Using , in place of \"|\"\n",
    "dmp_file=dmp_file.split(',')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def file_preprocess(file):\n",
    "    count=0\n",
    "    runcount=0\n",
    "    result={}\n",
    "    splitted_index_list=[]\n",
    "    splitted_value_list=[]\n",
    " \n",
    "    for index,item in enumerate(file):\n",
    "       \n",
    "        if index%4==0:\n",
    "            result[index+1]=file[index]\n",
    "        else:\n",
    "            result[index+1]=file[index]\n",
    "    return result\n",
    "\n",
    "preprocess_output=file_preprocess(dmp_file)\n",
    "\n",
    "        \n",
    "        \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3238651, 'Ageneiogarra,,scientificname,')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_dict={}\n",
    "itercount=0\n",
    "for index,item in enumerate(preprocess_output):\n",
    "    if index==1:\n",
    "        result_dict[itercount]=preprocess_output[index]+','+preprocess_output[index+1]+','+preprocess_output[index+2]+','+preprocess_output[index+3]\n",
    "       \n",
    "        itercount+=1\n",
    "    if index%4==0: \n",
    "        result_dict[itercount]=preprocess_output[index+1]+','+preprocess_output[index+2]+','+preprocess_output[index+3]+','+preprocess_output[index+4]\n",
    "        \n",
    "        itercount+=1\n",
    "    if index==len(preprocess_output)-4:\n",
    "        result_dict[itercount]=preprocess_output[index+1]+','+preprocess_output[index+2]+','+preprocess_output[index+3]+','+preprocess_output[index+4]\n",
    "       \n",
    "        itercount+=1\n",
    "        break\n",
    "result_dict.pop(0)\n",
    "result_dict.popitem()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get only scientific names and genbankcommonname\n",
    "count=0\n",
    "scientific_dict={}\n",
    "common_dict={}\n",
    "for k, v in list(result_dict.items()):\n",
    "    if 'scientificname' in v:\n",
    "        scientific_dict[count]=v\n",
    "        count+=1\n",
    "    else:\n",
    "        if 'genbankcommonname' in v:\n",
    "            common_dict[count]=v\n",
    "            count+=1\n",
    "          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get only 1,2 column only as 4th column is not needed all are redundant 'scientific name'\n",
    "scientific_dict_2={}\n",
    "for k, v in scientific_dict.items():\n",
    "    scientific_dict_2[v.split(',')[0]]=v.split(',')[1]\n",
    "common_dict_2={}\n",
    "for k, v in common_dict.items():\n",
    "    common_dict_2[v.split(',')[0]]=v.split(',')[1]\n",
    "               \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge commondict 2 and sc dict 2 into dataframe and merge\n",
    "scientific_df = pd.DataFrame(list(scientific_dict_2.items()),columns=['tax_id','scientific_name'])\n",
    "common_df = pd.DataFrame(list(common_dict_2.items()),columns=['tax_id','common_name'])\n",
    "final_df=pd.merge(scientific_df, common_df,how='left',left_on='tax_id',right_on='tax_id')\n",
    "final_df.common_name = final_df.common_name.fillna('NA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dataframe to csv conversion\n",
    "final_df.to_csv (r'C:\\Users\\GURU\\Desktop\\tax_data 26-3\\name.csv', index = False, header=True)\n",
    "\n",
    "###############################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################################################################\n",
    "#Nodes.dmp file conversion\n",
    "\n",
    "dmp_file = open(r'C:\\Users\\GURU\\Desktop\\tax_data 26-3\\nodes.dmp',\"r\", encoding=\"utf-8\").read()\n",
    "#dmp_file=dmp_file[0:1000]\n",
    "dmp_file = re.sub('\\s+', '', dmp_file)\n",
    "dmp_file = dmp_file.replace('|', ',')\n",
    "dmp_file=dmp_file.split(',')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def file_preprocess(file):\n",
    "    count=0\n",
    "    result={}\n",
    "    splitted_index_list=[]\n",
    "    splitted_value_list=[]\n",
    " \n",
    "    for index,item in enumerate(file):\n",
    "       \n",
    "        if index%18==0:\n",
    "            result[index+1]=file[index]\n",
    "        else:\n",
    "            result[index+1]=file[index]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_output=file_preprocess(dmp_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_item(i,item):\n",
    "    item_list=\"\"\n",
    "    if i==1:\n",
    "        for j in range(0,18):\n",
    "            item_list+=item[i+j]+','\n",
    "    if i%18==0:\n",
    "         for j in range(1,18):\n",
    "            item_list+=item[i+j]+','\n",
    "        \n",
    "    \n",
    "    return item_list\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2323131, '')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_dict={}\n",
    "itercount=0\n",
    "for index,item in enumerate(preprocess_output):\n",
    "    if index==1:\n",
    "        result_dict[itercount]=add_item(index,preprocess_output)\n",
    "       \n",
    "        itercount+=1\n",
    "    if index%18==0: \n",
    "        result_dict[itercount]=add_item(index,preprocess_output)\n",
    "        \n",
    "        itercount+=1\n",
    "    if index==len(preprocess_output)-18:\n",
    "        result_dict[itercount]=add_item(index,preprocess_output)\n",
    "       \n",
    "        itercount+=1\n",
    "        break\n",
    "result_dict.pop(0)\n",
    "result_dict.popitem()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To get the first 3 columns\n",
    "\n",
    "for k, v in result_dict.items():\n",
    "    result_dict[k]=v.split(',')[0]+','+v.split(',')[1]+','+v.split(',')[2]\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dict to csv file\n",
    "import csv\n",
    "my_dict = result_dict\n",
    "with open(r'C:\\Users\\GURU\\Desktop\\tax_data 26-3\\test_node.csv', 'w') as f:\n",
    "    for key in my_dict.keys():\n",
    "        f.write(\"%s\\n\"%(my_dict[key]))\n",
    "\n",
    "csv_file = pd.read_csv(r'C:\\Users\\GURU\\Desktop\\tax_data 26-3\\test_node.csv', \n",
    "                  sep=',', \n",
    "                  names=[\"tax_id\",\"parent tax_id\",\"rank\"])\n",
    "\n",
    "\n",
    "csv_file.to_csv(r'C:\\Users\\GURU\\Desktop\\tax_data 26-3\\node.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the files into two dataframes. First add parent rank to the existing node.csv\n",
    "df1 = pd.read_csv(r'C:\\Users\\GURU\\Desktop\\tax_data 26-3\\node.csv')\n",
    "df2 = pd.read_csv(r'C:\\Users\\GURU\\Desktop\\tax_data 26-3\\name.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the two dataframes,of (taxid,parentid,rank) and (taxid,scientificname,commonname) \n",
    "#using _ID column as key\n",
    "df3 = pd.merge(df1, df2, on = 'tax_id')\n",
    "#Modify first row\n",
    "df3.at[0,'parent tax_id']='0'\n",
    "df3.at[0,'rank']='norank'\n",
    "df3.common_name = df3.common_name.fillna('NA')\n",
    "\n",
    "# Write it to a new CSV file\n",
    "df3.to_csv(r'C:\\Users\\GURU\\Desktop\\tax_data 26-3\\Final.csv',encoding='utf-8', index=False)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
